{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.python.keras.layers import Activation, Dense, Conv2D, Flatten, MaxPooling2D, Input, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "#1. 데이터\n",
    "path = './_data/shopping/'\n",
    "train_set = pd.read_csv(path + 'train.csv', # + 명령어는 문자를 앞문자와 더해줌\n",
    "                        index_col=0) # index_col=n n번째 컬럼을 인덱스로 인식\n",
    "Weekly_Sales = train_set[['Weekly_Sales']]\n",
    "print(train_set)\n",
    "print(train_set.shape) # (6255, 12)\n",
    "\n",
    "test_set = pd.read_csv(path + 'test.csv', # 예측에서 쓸거임                \n",
    "                       index_col=0)\n",
    "print(test_set)\n",
    "print(test_set.shape) # (180, 11)\n",
    "\n",
    "print(train_set.columns)\n",
    "print(train_set.info()) # info 정보출력\n",
    "print(train_set.describe()) # describe 평균치, 중간값, 최소값 등등 출력\n",
    "\n",
    "train_set.isnull().sum().sort_values(ascending=False)\n",
    "test_set.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "######## 년, 월 ,일 분리 ############\n",
    "\n",
    "train_set[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(train_set.Date)]\n",
    "train_set[\"month\"] = [t.month for t in pd.DatetimeIndex(train_set.Date)]\n",
    "train_set['year'] = [t.year for t in pd.DatetimeIndex(train_set.Date)]\n",
    "\n",
    "test_set[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(test_set.Date)]\n",
    "test_set[\"month\"] = [t.month for t in pd.DatetimeIndex(test_set.Date)]\n",
    "test_set['year'] = [t.year for t in pd.DatetimeIndex(test_set.Date)]\n",
    "\n",
    "train_set.drop(['Date','Weekly_Sales'],axis=1,inplace=True) # 트레인 세트에서 데이트타임 드랍\n",
    "test_set.drop(['Date'],axis=1,inplace=True) # 트레인 세트에서 데이트타임 드랍\n",
    "\n",
    "print(train_set)\n",
    "print(test_set)\n",
    "##########################################\n",
    "\n",
    "# ####################원핫인코더###################\n",
    "\n",
    "df = pd.concat([train_set, test_set])\n",
    "print(df)\n",
    "\n",
    "alldata = pd.get_dummies(df, columns=['day','Store','month', 'year', 'IsHoliday'])\n",
    "print(alldata)\n",
    "\n",
    "train_set2 = alldata[:len(train_set)]\n",
    "test_set2 = alldata[len(train_set):]\n",
    "\n",
    "print(train_set2)\n",
    "print(test_set2)\n",
    "# train_set = pd.get_dummies(train_set, columns=['Store','month', 'year', 'IsHoliday'])\n",
    "# test_set = pd.get_dummies(test_set, columns=['Store','month', 'year', 'IsHoliday'])\n",
    "\n",
    "\n",
    "###############프로모션 결측치 처리###############\n",
    "\n",
    "train_set2 = train_set2.fillna(0)\n",
    "test_set2 = test_set2.fillna(0)\n",
    "\n",
    "print(train_set2)\n",
    "print(test_set2)\n",
    "\n",
    "##########################################\n",
    "\n",
    "train_set2 = pd.concat([train_set2, Weekly_Sales],axis=1)\n",
    "print(train_set2)\n",
    "\n",
    "x = train_set2.drop(['Weekly_Sales'], axis=1)\n",
    "y = train_set2['Weekly_Sales']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=66\n",
    "                                                    )\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "# scaler = MaxAbsScaler()\n",
    "# scaler = RobustScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "test_set2 = scaler.transform(test_set2)\n",
    "\n",
    "print(test_set2)\n",
    "\n",
    "# 2. 모델구성\n",
    "input1 = Input(shape=(77,))\n",
    "dense1 = Dense(100)(input1)\n",
    "batchnorm1 = BatchNormalization()(dense1)\n",
    "activ1 = Activation('relu')(batchnorm1)\n",
    "drp4 = Dropout(0.2)(activ1)\n",
    "dense2 = Dense(100)(drp4)\n",
    "batchnorm2 = BatchNormalization()(dense2)\n",
    "activ2 = Activation('relu')(batchnorm2)\n",
    "drp5 = Dropout(0.2)(activ2)\n",
    "dense3 = Dense(150)(drp5)\n",
    "batchnorm3 = BatchNormalization()(dense3)\n",
    "activ3 = Activation('relu')(batchnorm3)\n",
    "drp6 = Dropout(0.2)(activ3)\n",
    "dense4 = Dense(100)(drp6)\n",
    "batchnorm4 = BatchNormalization()(dense4)\n",
    "activ4 = Activation('relu')(batchnorm4)\n",
    "drp7 = Dropout(0.2)(activ4)\n",
    "output1 = Dense(1)(drp7)\n",
    "model = Model(inputs=input1, outputs=output1)   \n",
    "\n",
    "\n",
    "#3. 컴파일, 훈련\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import datetime\n",
    "date = datetime.datetime.now()\n",
    "date = date.strftime(\"%m%d_%H%M\") # 0707_1723\n",
    "print(date)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=30, mode='auto', verbose=1, \n",
    "                              restore_best_weights=True)        \n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=3000, batch_size=128,\n",
    "                 validation_split=0.3,\n",
    "                 callbacks=[earlyStopping],\n",
    "                 verbose=1)\n",
    "\n",
    "#4. 평가, 예측\n",
    "\n",
    "print(\"=============================1. 기본 출력=================================\")\n",
    "loss = model.evaluate(x_test, y_test)\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "def RMSE(a, b): \n",
    "    return np.sqrt(mean_squared_error(a, b))\n",
    "\n",
    "rmse = RMSE(y_test, y_predict)\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('loss : ', loss)\n",
    "print(\"RMSE : \", rmse)\n",
    "print('r2스코어 : ', r2)\n",
    "\n",
    "print(test_set2)\n",
    "\n",
    "y_summit = model.predict(test_set2)\n",
    "\n",
    "print(y_summit)\n",
    "print(y_summit.shape) # (180, 1)\n",
    "\n",
    "submission_set = pd.read_csv(path + 'sample_submission.csv', # + 명령어는 문자를 앞문자와 더해줌\n",
    "                             index_col=0) # index_col=n n번째 컬럼을 인덱스로 인식\n",
    "\n",
    "print(submission_set)\n",
    "\n",
    "submission_set['Weekly_Sales'] = y_summit\n",
    "print(submission_set)\n",
    "\n",
    "submission_set.to_csv(path + 'submission.csv', index = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf282gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5570794a6996fd16973774885d80e05bcf29b3031717e7c09f26aa6ac97c6540"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
